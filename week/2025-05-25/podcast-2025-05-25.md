Alex: Hello and welcome to Anand’s Weekly Codecast for the week of 25 May 2025!

Maya: We’re Alex and Maya, and today we’ll walk you through the highlights of Anand’s commits this week.

Alex: First up, let’s talk about the collection of handy little web apps that Anand runs, mostly Single Page Applications powered by LLMs.

Maya: This week, the big update is a new feature in the GitHub activity summarizer tool—it now recommends users right on the summary page!

Alex: Yes! Instead of just typing a username, you get a fancy dropdown list with interesting user suggestions. It makes exploring GitHub activities more interactive and fun.

Maya: That’s great for folks who want quick inspiration or to check out prominent contributors. It’s like giving you a little nudge on who to look up next.

Alex: Not just that, the summarizer also got a visual refresh with Bootstrap updated for better styling consistency. So it feels cleaner and more polished.

Maya: Also, the podcast generator web app got some solid love—now you can type your own podcast script, easily save your form settings with a nifty library, and you can clear all your saved data with a button.

Alex: I love how these improvements add flexibility—whether you want to craft your own narrative or start from AI-generated scripts, the UI adapts.

Maya: Plus, the podcast generator supports selecting different models and providers, like OpenAI, Azure, or local LLM setups, making it easier to customize your experience.

Alex: Exactly. The behind-the-scenes API changes let you pick any compatible provider, giving people more freedom and control.

Maya: This week also saw robust upgrades to a tiny library that keeps your form inputs saved across reloads, even explaining now how to save password fields safely.

Alex: That’s hugely helpful for web developers wanting forms that “remember” inputs without compromising sensitive fields by default.

Maya: Speaking of forms, there’s an enhancement that lets fields without a name but with an ID get saved too. That covers more use cases, making form persistence more reliable.

Alex: So overall, a push for better user experience consistency across tools, with solid code and smooth workflows.

Maya: Let’s switch gears to a fascinating new repository—the Story Network app.

Alex: Yes! Anand created a beautiful new visualization tool that shows where people, places, or entities pop up in stories and how they’re connected.

Maya: The big lift here was revamping the homepage to add an engaging introductory jumbotron and a dark mode toggle. Now, it’s both beautiful and friendly to your eyes.

Alex: Small but critical changes made the entity presence visuals more precise: bigger dots on the timelines, better table layout for correlations, and snappy transitions.

Maya: Using Bootstrap’s native colors for both light and dark mode means it’s consistent and accessible, not fiddly with separate themes.

Alex: And the addition of a dark mode toggle inside the navbar is a practical touch. Everyone loves being able to switch between themes easily.

Maya: Also, the app neatly fixed some bugs where entity toggles persisted incorrectly when switching stories. Now it's clean every time you jump back.

Alex: The demo even includes a rich example—the story of Les Misérables, showing all the key characters and their interactions. A great test of the tool’s power.

Maya: Next, let’s talk about the powerhouse tool for comparing large language models by price and performance.

Alex: This week, Anand added a cool new analysis script that fetches real-time throughput stats and calculates “billing rates.” It shows how much it costs per hour to run each LLM model based on tokens processed and token price.

Maya: It’s practical because everyone wonders not just which model is best on benchmarks, but how much it costs to really use one at scale.

Alex: Exactly, and this new script fetches batches of models from OpenRouter’s API, computes averages via efficient batching, and outputs a detailed JSON file with model prices, speeds, and estimated hourly bills.

Maya: Plus, the data was integrated into the main repo with fresh updated model stats—valuing quality alongside cost changes this May.

Alex: That continuous price-quality data helps developers and companies make smart choices balancing budgets and service levels.

Maya: Moving on to another very cool update—Anand’s public course content for Tools in Data Science at IIT Madras.

Alex: Nothing major, but some key formatting fixes in the docs to make reading smoother, plus updated deadlines for assignments.

Maya: That’s always important for students to stay on track, especially for this very rigorous and practical course.

Alex: Next, about the Google Datachat bot—Anand deployed the worker app that connects Google Chat to BigQuery, answering data questions using natural language.

Maya: This neat bot generates SQL queries behind the scenes, runs them against a public ecommerce dataset, then gives easy-to-understand answers right inside your chat.

Alex: Big setup update here was careful management of OAuth tokens, Google Service Account auth for secure queries, plus adding structure to the conversation flow and error handling.

Maya: The architecture and docs in the code explain how to set up the bot, link it with GCP and Cloudflare Workers, and add proper permissions. Perfect for organizations looking to empower users with data insight.

Alex: Now, for our final highlight, Anand refined the generative AI group’s podcast tools.

Maya: Yeah! The script now adds the podcast dialogue text as descriptions in the RSS feed, making each episode’s content more discoverable for listeners.

Alex: Also, the generation switched to using calendar weeks starting Sundays, which matches most people’s week view better.

Maya: Plus, there was a funny correction to the podcast hosts’ introductions to make the conversation sound natural. It helps polish the listening experience.

Alex: Before we sign off, Maya, got a quick pro tip for our listeners?

Maya: Absolutely! Here’s a quick tip you can try today: If you’re dealing with lots of AI agents or workflows calling multiple tools, use intent detection to route requests to the right specialized model or API.

Alex: That’s smart! I’d set up a small filtering layer that picks the best model for each query type—reducing latency and improving accuracy.

Maya: Yes, and it’s easier to tune than trying to train a big model to handle every task optimally.

Alex: Alright, for our wrap-up: Remember, small user experience improvements—like saving form data or adding dark mode toggle—can make a huge difference.

Maya: And don’t forget to keep an eye on real-world costs alongside capabilities when choosing large language models.

Maya: That’s all for this week on Anand’s Weekly Codecast.

Alex: See you next time!
