Alex: Hello and welcome to Anand’s Weekly Codecast for the week of 05 Oct 2025!
Maya: We’re Alex and Maya, and today we’ll walk you through the highlights of Anand’s commits this week.

Alex: Big week — Anand shipped a whole set of browser-history data stories for his personal "data stories" site. He added three interactive narratives: an Attention Clock that maps circadian focus, Rabbit Holes that traces long browsing chains, and Search Funnels that show whether a question reached an answer. He even included CSVs, specs for re-running the SQL, and a privacy review that flags what should not be published raw.
Maya: That was such a neat piece of work — he used LLMs to plan the analyses and Claude Code for visuals, but kept the data processing explicit. Why does that matter for people who want to learn from this?
Alex: Two big things: first, it’s a reproducible pattern — extract query logs, compute foreground time, cluster journeys, and hand off the visual aesthetic to a model designed for it. Second, the privacy review is a model for responsible publication: it points out domain-level deanonymization, raw search terms, and per-day granularities that can identify a person.
Maya: Practical idea: if you want to show personal telemetry, pre-aggregate and bucket sensitive fields — e.g., map domains to categories like "Email" or "Calendar", and smooth daily spikes to weekly bins. Also, use an explicit spec that tells the visualization model only the mood/effect you want, not the raw data. Non-obvious takeaway: letting different LLMs do what they’re best at — Codex/GPT-style for analysis, and Claude Code for design — saves time and gets prettier, more trustworthy outputs.

Alex: Next up, Anand updated the public materials for his "tools in data science" course. He added notes about new AI coding platforms — a Google multi-agent workspace and an OpenAI Codex Workspace — and soft-launched a new GA3 assessment and a project spec for an LLM-assisted code deployment assignment.
Maya: So this is both curriculum and tooling updates. What practical effect does it have for students?
Alex: It makes the course current: students get pointers to real team-level agent platforms, a rubric for a project where a signed request drives code generation and evaluation, and concrete CLI tools to practice with. The project spec also shifts away from signatures-only to simpler secrets and time-limited evaluation webhooks — more practical for classroom automation.
Maya: A useful tip for instructors: keep the assessment workflow minimal and deterministic — require a short webhook response, a Pages URL, and an automated test script. Non-obvious idea: design a round-2 adaptive request that targets a student’s repo and asks for a narrow change; it teaches iteration and secure verification.

Alex: On the engineering demo side, Anand added a Bootstrap Theme Picker tool to his small tools collection — it’s a bookmarklet and a preview UI that updates CSS variables live. He also expanded presets, added tests, and surfaced the tool on the homepage.
Maya: That’s the kind of tiny utility that saves so much fiddling when designing. Why is the bookmarklet approach smart here?
Alex: It’s low-friction: you drag a button into the bookmarks bar and you can preview palettes on any Bootstrap page without installing extensions. He also wrote tests that check the minified script is embedded and that changing a preset updates CSS variables — that’s rare for quick utility tools and raises quality.
Maya: Practical idea: if you build similar bookmarklets, bundle a small test harness and a preview page so non-technical users can try it without installation.

Alex: Anand also improved his LLM agent demo project a lot. He refactored tools so each can define render and renderResults functions, centralized code/JSON formatting, added a Google Search tool, wired tools to form environment variables, integrated saveform so the UI remembers form fields, and — importantly — moved to streaming agent output in the UI so you see reasoning, tool calls, and results in real time.
Maya: That’s a lot! What’s the biggest UX win?
Alex: Streaming. Instead of waiting for a long response you see the agent’s steps as they happen — reasoning blocks, tool invocations, and the outputs. That transparency helps debug and trust agents. The other win is modular tools with custom renderers — results are now readable titles/snippets instead of blobs of JSON.
Maya: Non-obvious takeaway: bind tools to a form-derived environment object so you can configure APIs in-page (e.g., Google API keys) without embedding secrets in code. Practical idea: start any agent project with a saveform-backed config panel so your dev keys and settings persist across sessions.

Alex: Over in Anand’s scripts and utilities repo, he modularized lots of CLI helpers: standalone jq scripts to convert Codex/Claude logs to Markdown, a whatsapp-to-thread jq transformer, a json-path finder, a post-mortem Python hook, and a cached GitHub scorer tool. He's also cleaned up shell aliases and systemd timers to automate daily transcript consolidation.
Maya: Those are the kind of ops-quality tools that make day-to-day research reproducible. What's a practical next step for someone using these?
Alex: Start by piping session logs into the jq scripts to extract readable markdown of your interactive LLM runs; it’s instant documentation. Also use the Python post-mortem hook in a dev virtualenv to start a debugger on exceptions — huge time-saver for debugging obscure pipeline failures.

Alex: Anand released a small but important update to a tiny library he maintains for persisting form fields. He added dropEmpty so clearing a input can remove the saved key, updated README examples, added tests, and bumped the package to 1.4.0 with package-lock disabled for easier installs.
Maya: That seems small but it changes UX — why care?
Alex: Because saved state UX can be surprising: users expect that clearing a field means “reset to default.” With dropEmpty you can make that semantic. He also added a test ensuring booleans like false are preserved while empty strings drop — good attention to edge cases.
Maya: Tip: when you build form persistence, treat empty string, null, and false differently — document the behavior clearly so integrators don’t get subtle bugs.

Alex: A few smaller but notable items: Anand added a reproducible JSON data generator for one repo — a python script that writes 50 JSON files and is wired into the deploy workflow — so static demo sites can regenerate fake data automatically. He also added participant feedback to a workshop talk page, upgraded the podcast prompt and model to a newer LLM and adjusted output parsing, and improved many teaching prompts and TIL notes.
Maya: Those are the iterative maintenance moves that keep a portfolio usable. Any quick privacy caveats from the browser-history work or the WhatsApp tools?
Alex: Yes — the browser-history commit includes an explicit privacy review that flags raw domain lists and raw search terms as high-risk. And the WhatsApp scraper had fixes to preserve reaction text and to avoid leaking phone numbers in system messages. Anand’s approach: run a privacy checklist, anonymize or bucket sensitive fields, and only publish redacted screenshots.

Maya: Time for listener tips. Quick, Alex — one actionable tip from today’s highlights?
Alex: If you publish personal telemetry or browsing analysis, run a privacy scan first: aggregate domains into categories, redact internal company hosts, and consider smoothing date granularity to weekly bins. Maya, how would you apply that if you wanted to share a weekly focus map?
Maya: I’d start by grouping domains into broad buckets — Email, Meetings, AI, Development — then produce the attention clock from those buckets. I’d also manually review any top domains and redact or generalize ones that are unique to employers or clients.

Maya: My tip: if you build small interactive tools or agents, start with streaming output in your UI and custom renderers for each tool — it makes debugging, trust and user comprehension much easier. Alex, how would you apply that to a prototype agent you were demoing?
Alex: I’d implement a tiny event stream that appends reasoning, tool calls, and results to the page as they come. For each tool, I’d add a short renderer: code blocks pretty-printed, search results as title + snippet links. That gives a demo vibe and reduces the “black box” feeling.

Alex: That’s a great wrap for the week — lots of practicality, a thread of responsibility, and a bunch of small UX wins.
Maya: Yep — Anand balanced research stories, teaching updates, and production tooling this week. Thanks for walking through it, Alex.
Alex: Thanks, Maya. And thanks to everyone listening — try one of the tips, and we’ll see what Anand ships next week.
Maya: Goodbye for the week — see you next Monday on Anand’s Weekly Codecast!
Alex: Bye!